{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP615 - Assignment Two Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "This cell contains all necessary imports for the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB # Added for completeness, as per assignment\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.csv')\n",
    "dftest = pd.read_csv('testing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: K-Nearest Neighbors (KNN) and Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2. Perform Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Overview and Integrity Check\n",
    "First, let's get a basic understanding of the dataset's structure, data types, and check for any missing or duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Training Set Information ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\\n--- Testing Set Information ---\")\n",
    "dftest.info()\n",
    "\n",
    "print('\\n\\n--- Null and Duplicate Value Check ---')\n",
    "print('\\nTraining Set:')\n",
    "print(f\"Total null values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Total duplicate values: {df.duplicated().sum()}\")\n",
    "\n",
    "print('\\nTesting Set:')\n",
    "print(f\"Total null values: {dftest.isnull().sum().sum()}\")\n",
    "print(f\"Total duplicate values: {dftest.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Distribution\n",
    "Visualize the distribution of the target variable (`class`) to check for any class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='class', data=df, order=df['class'].value_counts().index)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency (Count)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization: Feature Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Feature Variances\n",
    "Low-variance features may not be very informative. Let's visualize the spread of variances across all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.drop('class', axis=1)\n",
    "feature_variances = numeric_df.var()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(feature_variances, bins=30, edgecolor='black')\n",
    "plt.title('Histogram of Feature Variances')\n",
    "plt.xlabel('Variance')\n",
    "plt.ylabel('Number of Features (Frequency)')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Heatmap\n",
    "A correlation heatmap helps identify multicollinearity, where features are highly correlated with each other. This is especially important for models that assume feature independence, like Naïve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix,\n",
    "            annot=False,\n",
    "            cmap='coolwarm',\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            center=0)\n",
    "plt.title('Correlation Heatmap of Features', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots for Selected Features by Class\n",
    "Let's examine the distributions of a few potentially important features across the different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = 'class'\n",
    "selected_features_for_boxplot = ['NDVI', 'Mean_NIR', 'GLCM2', 'Bright', 'Mean_R']\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, feature_name in enumerate(selected_features_for_boxplot):\n",
    "   plt.subplot(2, 3, i + 1)\n",
    "   sns.boxplot(x=target_column_name, y=feature_name, data=df)\n",
    "   plt.title(f'Boxplot of {feature_name}\\nby {target_column_name}')\n",
    "   plt.xlabel(target_column_name)\n",
    "   plt.ylabel(feature_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3. Feature Selection and Analysis\n",
    "We use the ANOVA F-test (`f_classif`) to identify the top 5 features that have the strongest relationship with the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=min(5, X.shape[1]))\n",
    "selector.fit(X, y)\n",
    "\n",
    "selected_features_indices = selector.get_support(indices=True)\n",
    "top_features_names = X.columns[selected_features_indices].tolist()\n",
    "\n",
    "print(\"Top 5 features by F score:\")\n",
    "for name in top_features_names:\n",
    "    print(f\"- {name}\")\n",
    "\n",
    "df_plot_selected = X[top_features_names].copy()\n",
    "df_plot_selected['class'] = y.reset_index(drop=True)\n",
    "class_order_for_plot = df['class'].value_counts().index\n",
    "\n",
    "for feature_name in top_features_names:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x='class', y=feature_name, data=df_plot_selected, order=class_order_for_plot)\n",
    "    plt.title(f'Distribution of  {feature_name} by Class')\n",
    "    plt.ylabel(f'{feature_name}')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing for Models\n",
    "Here, we define our training and test sets and scale the features using `StandardScaler`. Scaling is crucial for distance-based algorithms like KNN and helps with the convergence of models like MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop('class', axis=1)\n",
    "y_train = df['class']\n",
    "\n",
    "X_test = dftest.drop('class', axis= 1)\n",
    "y_test = dftest['class']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(f\"Training data scaled. Shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test data scaled. Shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A6. K-Nearest Neighbors (KNN) Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Optimal 'k' using Cross-Validation\n",
    "We'll test a range of `k` values and use 5-fold cross-validation to find the value that yields the highest average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1, 21)\n",
    "cv_scores = []\n",
    "\n",
    "print(\"--- Finding Best K using 5-Fold Cross-Validation ---\")\n",
    "for k_val in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_val)\n",
    "    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    print(f\"k={k_val}, CV Mean Accuracy: {scores.mean():.4f}\")\n",
    "\n",
    "best_k_cv = k_range[np.argmax(cv_scores)]\n",
    "print(f\"\\nBest k based on cross-validation: {best_k_cv} with CV accuracy: {max(cv_scores):.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, cv_scores, marker='o', linestyle='dashed')\n",
    "plt.title('KNN Performance for different k values (Cross-Validation)')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Mean Cross-Validated Accuracy')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final KNN Model Evaluation\n",
    "Now we train the KNN model using the best `k` found and evaluate its performance on the unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = best_k_cv\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"KNN Model Accuracy (k={k}): {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "class_labels = np.unique(np.concatenate((y_test, y_pred_knn)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_knn, labels=class_labels)\n",
    "\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = class_labels,\n",
    "                     columns = class_labels)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_df,\n",
    "            annot=True,      \n",
    "            fmt='d',         \n",
    "            cmap='Blues',    \n",
    "            linewidths=.5,\n",
    "            linecolor='gray',\n",
    "            cbar=True)\n",
    "\n",
    "plt.title(f'Confusion Matrix for KNN (k={best_k_cv})', fontsize=15)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Exploring Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2 & B3. Baseline Model (Single Hidden Layer) and Loss Tracking\n",
    "We use `GridSearchCV` to find the optimal number of neurons (k) and iterations for a single-layer MLP. Then, we train a new model with these parameters and plot its learning curves to observe the training loss and validation accuracy over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Part B(b): Finding Best Parameters for Single-Layer MLP ---\")\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(k,) for k in range(5, 26, 5)], # [5, 10, 15, 20, 25]\n",
    "    'max_iter': [50, 100, 150, 200, 250]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=MLPClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=10,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"--- Starting GridSearchCV to find best hyperparameters ---\")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\n--- Grid Search Results ---\")\n",
    "best_params_single_layer = grid_search.best_params_\n",
    "baseline_accuracy = grid_search.best_score_\n",
    "print(f\"Best parameters found: {best_params_single_layer}\")\n",
    "print(f\"Highest 10-fold CV Accuracy: {baseline_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n--- Part B(c): Creating and training the optimal model for plotting ---\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "optimal_mlp = MLPClassifier(\n",
    "    **best_params_single_layer,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=15\n",
    ")\n",
    "\n",
    "optimal_mlp.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "final_accuracy = optimal_mlp.score(X_test_scaled, y_test_encoded)\n",
    "print(f\"Final test accuracy of the optimal model: {final_accuracy:.4f}\")\n",
    "print(f\"Number of iterations run (due to early stopping): {optimal_mlp.n_iter_}\")\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.plot(optimal_mlp.loss_curve_, label='Training Loss', color='blue')\n",
    "k_mlp = optimal_mlp.hidden_layer_sizes[0]\n",
    "plt.title(f'Optimal MLP (k={k_mlp}) - Loss & Validation Accuracy vs. Iterations', fontsize=14)\n",
    "plt.xlabel('Iteration (Epoch)', fontsize=12)\n",
    "plt.ylabel('Training Loss', color='blue', fontsize=12)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(optimal_mlp.validation_scores_, label='Validation Accuracy', color='green', linestyle='--')\n",
    "ax2.set_ylabel('Validation Accuracy', color='green', fontsize=12)\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B4. Experimenting with Two Hidden Layers\n",
    "Here, we experiment with splitting the total number of neurons (`k` from the best single-layer model) across two hidden layers to see if a deeper architecture improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k_from_single = best_params_single_layer['hidden_layer_sizes'][0]\n",
    "iterations_to_use = best_params_single_layer['max_iter']\n",
    "\n",
    "print(f\"\\n--- Part B(d): Experimenting with Two Hidden Layers ---\")\n",
    "print(f\"Total neurons to distribute: {best_k_from_single}\")\n",
    "print(f\"Iterations for each model: {iterations_to_use}\\n\")\n",
    "\n",
    "results_table_data = []\n",
    "\n",
    "for n2_neurons in range(1, best_k_from_single):\n",
    "    n1_neurons = best_k_from_single - n2_neurons\n",
    "    layer_config = (n1_neurons, n2_neurons)\n",
    "\n",
    "    mlp_model = MLPClassifier(\n",
    "        hidden_layer_sizes=layer_config,\n",
    "        max_iter=iterations_to_use,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    cv_scores = cross_val_score(mlp_model, X_train_scaled, y_train, cv=10, scoring='accuracy', n_jobs=1)\n",
    "    avg_accuracy = np.mean(cv_scores)\n",
    "\n",
    "    results_table_data.append({\n",
    "        'config': f\"({n1_neurons}, {n2_neurons})\",\n",
    "        'accuracy': avg_accuracy\n",
    "    })\n",
    "    print(f\"Configuration: {layer_config}, Avg 10-fold CV Accuracy: {avg_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Summary Table for Two-Layer Configurations ---\")\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"| Neuron Combination | Avg CV Accuracy    |\")\n",
    "print(\"|--------------------|--------------------|\")\n",
    "\n",
    "best_two_layer_config = \"\"\n",
    "best_two_layer_accuracy = 0.0\n",
    "\n",
    "for result in results_table_data:\n",
    "    print(f\"| {result['config']:<18} | {result['accuracy']:.4f}           |\")\n",
    "    if result['accuracy'] > best_two_layer_accuracy:\n",
    "        best_two_layer_accuracy = result['accuracy']\n",
    "        best_two_layer_config = result['config']\n",
    "\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "print(\"\\n--- Final Comparison ---\")\n",
    "print(f\"Best single-layer baseline accuracy (from Part B(b)): {baseline_accuracy:.4f}\")\n",
    "print(f\"Best two-layer configuration found: {best_two_layer_config} with an accuracy of {best_two_layer_accuracy:.4f}\")\n",
    "\n",
    "if best_two_layer_accuracy > baseline_accuracy:\n",
    "    print(\"Conclusion: Adding a second hidden layer provided an improvement.\")\n",
    "else:\n",
    "    print(\"Conclusion: The single-layer architecture remains the best performing model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
